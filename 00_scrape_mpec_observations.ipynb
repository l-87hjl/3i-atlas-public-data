{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/l-87hjl/3i-atlas-public-data/blob/main/00_scrape_mpec_observations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZazZMz8yHi4F"
      },
      "source": [
        "# 3I/ATLAS MPEC Observation Scraper\n",
        "\n",
        "## Purpose\n",
        "Scrapes astrometric observations for interstellar comet **3I/ATLAS** from the Minor Planet Center (MPC) database and creates two standardized CSV outputs for the public data repository.\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è CRITICAL: J2000 COORDINATE SYSTEM\n",
        "\n",
        "**All positional data (RA/Dec) from MPC is in the J2000.0 reference frame.**\n",
        "\n",
        "- **Equinox**: J2000.0 (January 1, 2000, 12:00 TT)\n",
        "- **Reference Frame**: International Celestial Reference Frame (ICRF)\n",
        "- **Coordinate System**: Equatorial (Right Ascension, Declination)\n",
        "\n",
        "**This is the same coordinate system used by JPL Horizons** when you query with the standard settings. When comparing MPEC observations to Horizons ephemeris, both datasets are already in J2000, so **no coordinate transformation is required**.\n",
        "\n",
        "**Why this matters downstream:**\n",
        "- Residual calculations (Observed - Computed) assume matching coordinate frames\n",
        "- Any external catalogs or reference stars must also be in J2000\n",
        "- Precession/nutation corrections are NOT needed for epoch matching\n",
        "- Proper motion corrections may still be needed for field stars\n",
        "\n",
        "---\n",
        "\n",
        "## Data Source\n",
        "- **URL**: https://minorplanetcenter.net/db_search/show_object?object_id=3I\n",
        "- **Object**: 3I/ATLAS (interstellar comet, discovered 2025)\n",
        "- **Date Range**: Customizable (default: earliest available ‚Üí +14 days)\n",
        "- **Rate Limit**: Conservative scraping with delays to respect MPC servers\n",
        "\n",
        "---\n",
        "\n",
        "## Outputs\n",
        "\n",
        "### 1. `observations_MPEC.csv` (Full Data)\n",
        "Complete observation records with all available fields:\n",
        "- `timestamp_utc`: UTC observation time (ISO 8601 format)\n",
        "- `observatory_code`: MPC 3-character observatory code\n",
        "- `ra_j2000_deg`: Right Ascension in decimal degrees (J2000.0)\n",
        "- `dec_j2000_deg`: Declination in decimal degrees (J2000.0)\n",
        "- `magnitude`: Apparent magnitude (if reported)\n",
        "- `reference`: MPEC reference identifier\n",
        "\n",
        "### 2. `observations_timestamp_observatory_only.csv` (Minimal Index)\n",
        "Lightweight index file containing only:\n",
        "- `timestamp_utc`: UTC observation time\n",
        "- `observatory_code`: MPC observatory code\n",
        "\n",
        "Used for quick timestamp/observatory lookups without loading full positional data.\n",
        "\n",
        "---\n",
        "\n",
        "## Usage\n",
        "1. Run all cells in order\n",
        "2. Enter desired date range when prompted (or accept defaults)\n",
        "3. Review summary statistics\n",
        "4. Download generated CSV files to your local machine\n",
        "5. Upload to `3i-atlas-public-data/observations/` repository\n",
        "\n",
        "---\n",
        "\n",
        "## Notes\n",
        "- **Maximum recommended range**: 14 days per run (to avoid server overload)\n",
        "- **Total observations available**: 5000+ (as of December 2025)\n",
        "- **Observatories**: 97+ contributing sites worldwide\n",
        "- **Coordinate precision**: Typically 0.01\" - 0.1\" depending on observatory\n",
        "- **No data filtering applied**: Raw observations preserved as reported by MPC\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "p7TcgTAkHi4I"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q requests beautifulsoup4 pandas lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXQA0gvWHi4K",
        "outputId": "7d038882-9b31-447a-c55c-3bae3139326c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ArkAQxZOHi4K"
      },
      "source": [
        "## Configuration & Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5K3VRFFRHi4L",
        "outputId": "03e85080-e272-462f-dc6a-8019dcb5072f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helper functions defined\n"
          ]
        }
      ],
      "source": [
        "# MPC 3I/ATLAS permalink\n",
        "MPC_URL = \"https://minorplanetcenter.net/db_search/show_object?utf8=%E2%9C%93&object_id=3I\"\n",
        "\n",
        "# Headers for polite scraping\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Scientific Research; 3I/ATLAS Analysis) AppleWebKit/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "}\n",
        "\n",
        "def parse_ra_to_degrees(ra_str: str) -> float:\n",
        "    \"\"\"\n",
        "    Convert RA from HH:MM:SS.SS format to decimal degrees (J2000).\n",
        "\n",
        "    Args:\n",
        "        ra_str: Right Ascension in format \"HH:MM:SS.SS\" or \"HH MM SS.SS\"\n",
        "\n",
        "    Returns:\n",
        "        RA in decimal degrees (0-360)\n",
        "    \"\"\"\n",
        "    ra_str = ra_str.strip().replace(':', ' ')\n",
        "    parts = ra_str.split()\n",
        "\n",
        "    hours = float(parts[0])\n",
        "    minutes = float(parts[1]) if len(parts) > 1 else 0.0\n",
        "    seconds = float(parts[2]) if len(parts) > 2 else 0.0\n",
        "\n",
        "    # Convert to degrees: 1 hour = 15 degrees\n",
        "    degrees = (hours + minutes/60.0 + seconds/3600.0) * 15.0\n",
        "    return round(degrees, 8)\n",
        "\n",
        "def parse_dec_to_degrees(dec_str: str) -> float:\n",
        "    \"\"\"\n",
        "    Convert Dec from ¬±DD:MM:SS.S format to decimal degrees (J2000).\n",
        "\n",
        "    Args:\n",
        "        dec_str: Declination in format \"¬±DD:MM:SS.S\" or \"¬±DD MM SS.S\"\n",
        "\n",
        "    Returns:\n",
        "        Dec in decimal degrees (-90 to +90)\n",
        "    \"\"\"\n",
        "    dec_str = dec_str.strip().replace(':', ' ')\n",
        "\n",
        "    # Handle sign\n",
        "    sign = -1.0 if dec_str.startswith('-') else 1.0\n",
        "    dec_str = dec_str.lstrip('+-')\n",
        "\n",
        "    parts = dec_str.split()\n",
        "    degrees = float(parts[0])\n",
        "    minutes = float(parts[1]) if len(parts) > 1 else 0.0\n",
        "    seconds = float(parts[2]) if len(parts) > 2 else 0.0\n",
        "\n",
        "    # Convert to decimal degrees\n",
        "    decimal = degrees + minutes/60.0 + seconds/3600.0\n",
        "    return round(sign * decimal, 8)\n",
        "\n",
        "def parse_observation_date(date_str: str) -> datetime:\n",
        "    \"\"\"\n",
        "    Parse MPC observation date to datetime object.\n",
        "\n",
        "    Args:\n",
        "        date_str: Date in format \"YYYY MM DD.ddddd\" (UTC)\n",
        "\n",
        "    Returns:\n",
        "        datetime object in UTC\n",
        "    \"\"\"\n",
        "    parts = date_str.strip().split()\n",
        "    year = int(parts[0])\n",
        "    month = int(parts[1])\n",
        "    day_decimal = float(parts[2])\n",
        "\n",
        "    day = int(day_decimal)\n",
        "    fraction = day_decimal - day\n",
        "\n",
        "    dt = datetime(year, month, day)\n",
        "    dt += timedelta(days=fraction)\n",
        "\n",
        "    return dt\n",
        "\n",
        "print(\"‚úÖ Helper functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcY5VtpOHi4L"
      },
      "source": [
        "## Fetch Object Summary from MPC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mNUEQbnlHi4M",
        "outputId": "0bd46430-0dfb-42bb-8f44-eb6c63b55866"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching object summary from MPC...\n",
            "    URL: https://minorplanetcenter.net/db_search/show_object?utf8=%E2%9C%93&object_id=3I\n",
            "\n",
            "======================================================================\n",
            "OBJECT CONFIRMATION\n",
            "======================================================================\n",
            "Name:               Orbit\n",
            "Total Observations: Unknown\n",
            "Coordinate System:  J2000.0 (ICRF equatorial)\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "def get_object_summary():\n",
        "    \"\"\"\n",
        "    Fetch 3I/ATLAS object summary and total observation count from MPC.\n",
        "    \"\"\"\n",
        "    print(f\"üîç Fetching object summary from MPC...\")\n",
        "    print(f\"    URL: {MPC_URL}\")\n",
        "\n",
        "    response = requests.get(MPC_URL, headers=HEADERS, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    # Extract object name\n",
        "    title = soup.find('h2')\n",
        "    object_name = title.text.strip() if title else \"3I/ATLAS\"\n",
        "\n",
        "    # Try to find observation count\n",
        "    obs_count = \"Unknown\"\n",
        "    for text in soup.stripped_strings:\n",
        "        if 'observation' in text.lower():\n",
        "            match = re.search(r'(\\d+)\\s+observation', text, re.IGNORECASE)\n",
        "            if match:\n",
        "                obs_count = match.group(1)\n",
        "                break\n",
        "\n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"OBJECT CONFIRMATION\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Name:               {object_name}\")\n",
        "    print(f\"Total Observations: {obs_count}\")\n",
        "    print(f\"Coordinate System:  J2000.0 (ICRF equatorial)\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "\n",
        "    return object_name, obs_count\n",
        "\n",
        "# Execute\n",
        "obj_name, total_obs = get_object_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjTrONhtHi4M"
      },
      "source": [
        "## User Input: Date Range Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZAbLnwjHi4M",
        "outputId": "64bd16f0-e3f0-476f-a778-5b0a17968ba7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ DATE RANGE SELECTION\n",
            "======================================================================\n",
            "Enter the date range for observations to scrape.\n",
            "Default start: 2025-07-15\n",
            "Recommended max span: 14 days per run\n",
            "\n",
            "Start date (YYYY-MM-DD) [2025-07-15]: 2025-12-18\n",
            "Number of days to scrape [14]: 14\n",
            "\n",
            "‚úÖ Selected Range:\n",
            "   Start: 2025-12-18\n",
            "   End:   2026-01-01\n",
            "   Span:  14 days\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Default values\n",
        "DEFAULT_START = \"2025-07-15\"  # Approximate discovery date range\n",
        "DEFAULT_DAYS = 14\n",
        "\n",
        "print(\"\\nüìÖ DATE RANGE SELECTION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Enter the date range for observations to scrape.\")\n",
        "print(f\"Default start: {DEFAULT_START}\")\n",
        "print(f\"Recommended max span: {DEFAULT_DAYS} days per run\\n\")\n",
        "\n",
        "# Get user input\n",
        "start_date_str = input(f\"Start date (YYYY-MM-DD) [{DEFAULT_START}]: \").strip()\n",
        "if not start_date_str:\n",
        "    start_date_str = DEFAULT_START\n",
        "\n",
        "days_str = input(f\"Number of days to scrape [{DEFAULT_DAYS}]: \").strip()\n",
        "if not days_str:\n",
        "    num_days = DEFAULT_DAYS\n",
        "else:\n",
        "    num_days = int(days_str)\n",
        "\n",
        "# Parse dates\n",
        "start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
        "end_date = start_date + timedelta(days=num_days)\n",
        "\n",
        "print(f\"\\n‚úÖ Selected Range:\")\n",
        "print(f\"   Start: {start_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"   End:   {end_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"   Span:  {num_days} days\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qw0TNwzpHi4N",
        "outputId": "0701c309-32c9-4144-812a-a9f9b6550371"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è±Ô∏è  TIMING ESTIMATE\n",
            "======================================================================\n",
            "For 14 days of observations:\n",
            "  Expected scraping time: 7.0 - 14.0 minutes\n",
            "  Approximate rate: ~30-60 seconds per day\n",
            "\n",
            "‚ö†Ô∏è  The scraping cell may appear frozen for several minutes.\n",
            "    This is NORMAL! Progress messages will appear as parsing completes.\n",
            "    Larger date ranges = longer wait times.\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate timing estimate\n",
        "estimate_min = num_days * 0.5\n",
        "estimate_max = num_days * 1.0\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  TIMING ESTIMATE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"For {num_days} days of observations:\")\n",
        "print(f\"  Expected scraping time: {estimate_min:.1f} - {estimate_max:.1f} minutes\")\n",
        "print(f\"  Approximate rate: ~30-60 seconds per day\")\n",
        "print(f\"\")\n",
        "print(f\"‚ö†Ô∏è  The scraping cell may appear frozen for several minutes.\")\n",
        "print(f\"    This is NORMAL! Progress messages will appear as parsing completes.\")\n",
        "print(f\"    Larger date ranges = longer wait times.\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGLHAEU1Hi4N"
      },
      "source": [
        "## Scrape Observations from MPC Table\n",
        "\n",
        "**Note**: This scrapes the HTML observation table. Each row contains:\n",
        "- Date (UT) in YYYY MM DD.ddddd format\n",
        "- J2000 RA in HH:MM:SS.SS format\n",
        "- J2000 Dec in ¬±DD:MM:SS.S format\n",
        "- Magnitude (optional)\n",
        "- Observatory code (3-character MPC designation)\n",
        "- Reference (MPEC identifier)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚è±Ô∏è Expected Duration\n",
        "- **Initial page load**: 2-5 seconds (polite delay to respect MPC servers)\n",
        "- **Parsing time**: Approximately **20-40 seconds per day** of observations\n",
        "- **For 14-day range**: Expect **5-10 minutes total**\n",
        "- **Actual time varies** based on:\n",
        "  - Network speed\n",
        "  - MPC server response time\n",
        "  - Number of observations in date range\n",
        "  - HTML table complexity\n",
        "\n",
        "**Don't panic if it seems frozen!** The MPC page can be large (5000+ observations). Progress messages will appear as parsing completes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M0anXHLRHi4N",
        "outputId": "bd0a9bc6-4868-4d19-ce1b-383fa77d0d6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nüåê Scraping observations from MPC...\n",
            "‚è±Ô∏è  Estimated time: 7.0-14.0 minutes for 14 days\n",
            "    (Network speed and server response may vary)\n",
            "    This is normal - the page is large! Please wait...\\n\n",
            "    ‚¨áÔ∏è  Fetching MPC page...\n",
            "    ‚úÖ Page downloaded (1636 KB)\n",
            "    üîç Parsing HTML table...\n",
            "    üìä Processing observations...\n",
            "    Found 5816 total observation rows in table\n",
            "       ... 100 observations matched so far\n",
            "\n",
            "‚úÖ Scraped 157 observations in date range\n"
          ]
        }
      ],
      "source": [
        "def scrape_observations(start_dt: datetime, end_dt: datetime) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Scrape MPC observations for 3I/ATLAS within specified date range.\n",
        "\n",
        "    Returns:\n",
        "        List of observation dictionaries with J2000 coordinates\n",
        "    \"\"\"\n",
        "    num_days = (end_dt - start_dt).days\n",
        "    estimated_minutes = num_days * 0.5  # Rough estimate: ~30 sec/day = 0.5 min/day\n",
        "\n",
        "    print(f\"\\\\nüåê Scraping observations from MPC...\")\n",
        "    print(f\"‚è±Ô∏è  Estimated time: {estimated_minutes:.1f}-{estimated_minutes*2:.1f} minutes for {num_days} days\")\n",
        "    print(f\"    (Network speed and server response may vary)\")\n",
        "    print(f\"    This is normal - the page is large! Please wait...\\\\n\")\n",
        "\n",
        "    time.sleep(2)  # Polite delay\n",
        "    print(f\"    ‚¨áÔ∏è  Fetching MPC page...\")\n",
        "\n",
        "    response = requests.get(MPC_URL, headers=HEADERS, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    print(f\"    ‚úÖ Page downloaded ({len(response.content)//1024} KB)\")\n",
        "\n",
        "    print(f\"    üîç Parsing HTML table...\")\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    # Find observation table\n",
        "    tables = soup.find_all('table')\n",
        "    obs_table = None\n",
        "\n",
        "    for table in tables:\n",
        "        # Look for table with observation headers\n",
        "        headers = table.find_all('th')\n",
        "        if any('Date' in th.text and 'RA' in str(table) for th in headers):\n",
        "            obs_table = table\n",
        "            break\n",
        "\n",
        "    if not obs_table:\n",
        "        raise ValueError(\"Could not find observation table on MPC page\")\n",
        "\n",
        "    print(f\"    üìä Processing observations...\")\n",
        "    observations = []\n",
        "    rows = obs_table.find_all('tr')[1:]  # Skip header row\n",
        "    total_rows = len(rows)\n",
        "    print(f\"    Found {total_rows} total observation rows in table\")\n",
        "\n",
        "    processed = 0\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) < 5:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Parse observation date\n",
        "            date_str = cols[0].text.strip()\n",
        "            obs_dt = parse_observation_date(date_str)\n",
        "\n",
        "            # Filter by date range\n",
        "            if not (start_dt <= obs_dt < end_dt):\n",
        "                continue\n",
        "\n",
        "            # Extract fields\n",
        "            ra_str = cols[1].text.strip()\n",
        "            dec_str = cols[2].text.strip()\n",
        "            mag_str = cols[3].text.strip()\n",
        "            location = cols[4].text.strip()  # Observatory code\n",
        "            reference = cols[5].text.strip() if len(cols) > 5 else \"\"\n",
        "\n",
        "            # Convert coordinates to decimal degrees (J2000)\n",
        "            ra_deg = parse_ra_to_degrees(ra_str)\n",
        "            dec_deg = parse_dec_to_degrees(dec_str)\n",
        "\n",
        "            # Parse magnitude (may be empty)\n",
        "            magnitude = None\n",
        "            if mag_str and mag_str != '‚Äî':\n",
        "                try:\n",
        "                    magnitude = float(mag_str)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            obs = {\n",
        "                'timestamp_utc': obs_dt.isoformat(),\n",
        "                'observatory_code': location,\n",
        "                'ra_j2000_deg': ra_deg,\n",
        "                'dec_j2000_deg': dec_deg,\n",
        "                'magnitude': magnitude,\n",
        "                'reference': reference\n",
        "            }\n",
        "\n",
        "            observations.append(obs)\n",
        "            processed += 1\n",
        "\n",
        "            # Progress indicator every 100 observations\n",
        "            if processed % 100 == 0:\n",
        "                print(f\"       ... {processed} observations matched so far\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Warning: Failed to parse row: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\n‚úÖ Scraped {len(observations)} observations in date range\")\n",
        "    return observations\n",
        "\n",
        "# Execute scraping\n",
        "observations = scrape_observations(start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIp3VyzGHi4O"
      },
      "source": [
        "## Create Output DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qTw0_zWEHi4O",
        "outputId": "84b758e9-8a06-4683-be8e-ff559715d4ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä DATASET SUMMARY\n",
            "======================================================================\n",
            "Total observations:  157\n",
            "Date range:          2025-12-18T00:35:55.507200 to 2025-12-23T03:25:15.888000\n",
            "Observatories:       33 unique sites\n",
            "Coordinate system:   J2000.0 equatorial (RA/Dec)\n",
            "======================================================================\n",
            "\n",
            "üìã Sample observations (first 5):\n",
            "                timestamp_utc                       observatory_code  \\\n",
            "0  2025-12-18T00:35:55.507200  M09 ‚Äì Observatory Gromme - Oudsbergen   \n",
            "1  2025-12-18T00:42:00.028800                            C23 ‚Äì Olmen   \n",
            "2  2025-12-18T00:45:57.628800  M09 ‚Äì Observatory Gromme - Oudsbergen   \n",
            "3  2025-12-18T00:55:37.718400  M09 ‚Äì Observatory Gromme - Oudsbergen   \n",
            "4  2025-12-18T01:03:34.041600                            C23 ‚Äì Olmen   \n",
            "\n",
            "   ra_j2000_deg  dec_j2000_deg magnitude  reference  \n",
            "0    162.942558       6.616783      None   MPEC Y51  \n",
            "1    162.937621       6.618531      None  MPEC Y151  \n",
            "2    162.934492       6.619500      None   MPEC Y51  \n",
            "3    162.926683       6.622164      None   MPEC Y51  \n",
            "4    162.920271       6.624431      None  MPEC Y151  \n",
            "\n",
            "üìã Observatory distribution:\n",
            "observatory_code\n",
            "W50 ‚Äì Apex                                               27\n",
            "C23 ‚Äì Olmen                                               9\n",
            "290 ‚Äì Mt. Graham-VATT                                     8\n",
            "Q21 ‚Äì Southern Utsunomiya                                 7\n",
            "U76 ‚Äì Maury Lewin Observatory, Glendora                   6\n",
            "213 ‚Äì Observatorio Montcabre                              6\n",
            "G05 ‚Äì Piconcillo, Sierra Morena                           6\n",
            "V21 ‚Äì Cewanee Observatory at DSNM                         5\n",
            "C82 ‚Äì Osservatorio Astronomico Nastro Verde, Sorrento     5\n",
            "M73 ‚Äì Eden Emirates Observatory, Abu Dhabi                5\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if len(observations) == 0:\n",
        "    print(\"\\n‚ö†Ô∏è  No observations found in specified date range!\")\n",
        "    print(\"   Try adjusting the start date or expanding the date range.\")\n",
        "else:\n",
        "    # Full observation dataset\n",
        "    df_full = pd.DataFrame(observations)\n",
        "\n",
        "    # Minimal timestamp/observatory index\n",
        "    df_index = df_full[['timestamp_utc', 'observatory_code']].copy()\n",
        "\n",
        "    # Sort by timestamp\n",
        "    df_full = df_full.sort_values('timestamp_utc').reset_index(drop=True)\n",
        "    df_index = df_index.sort_values('timestamp_utc').reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\nüìä DATASET SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total observations:  {len(df_full)}\")\n",
        "    print(f\"Date range:          {df_full['timestamp_utc'].min()} to {df_full['timestamp_utc'].max()}\")\n",
        "    print(f\"Observatories:       {df_full['observatory_code'].nunique()} unique sites\")\n",
        "    print(f\"Coordinate system:   J2000.0 equatorial (RA/Dec)\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Show sample\n",
        "    print(\"\\nüìã Sample observations (first 5):\")\n",
        "    print(df_full.head())\n",
        "\n",
        "    print(\"\\nüìã Observatory distribution:\")\n",
        "    print(df_full['observatory_code'].value_counts().head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAdVPrLdHi4O"
      },
      "source": [
        "## Save Output Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo3J6y0NHi4P",
        "outputId": "1ec724ee-7593-4296-8fdd-e1f8f80099fd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üíæ FILES SAVED\n",
            "======================================================================\n",
            "Full dataset:  observations_MPEC_20251218_20260101.csv\n",
            "               (157 rows, 6 columns)\n",
            "\n",
            "Index file:    observations_timestamp_observatory_only_20251218_20260101.csv\n",
            "               (157 rows, 2 columns)\n",
            "======================================================================\n",
            "\n",
            "‚úÖ COMPLETE! Download the files from the Colab file browser (left sidebar).\n",
            "   Upload to: 3i-atlas-public-data/observations/\n"
          ]
        }
      ],
      "source": [
        "if len(observations) > 0:\n",
        "    # Generate filenames with date range\n",
        "    date_suffix = f\"{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}\"\n",
        "\n",
        "    filename_full = f\"observations_MPEC_{date_suffix}.csv\"\n",
        "    filename_index = f\"observations_timestamp_observatory_only_{date_suffix}.csv\"\n",
        "\n",
        "    # Save CSVs\n",
        "    df_full.to_csv(filename_full, index=False, float_format='%.8f')\n",
        "    df_index.to_csv(filename_index, index=False)\n",
        "\n",
        "    print(f\"\\nüíæ FILES SAVED\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Full dataset:  {filename_full}\")\n",
        "    print(f\"               ({len(df_full)} rows, {df_full.shape[1]} columns)\")\n",
        "    print(f\"\")\n",
        "    print(f\"Index file:    {filename_index}\")\n",
        "    print(f\"               ({len(df_index)} rows, {df_index.shape[1]} columns)\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    print(\"\\n‚úÖ COMPLETE! Download the files from the Colab file browser (left sidebar).\")\n",
        "    print(\"   Upload to: 3i-atlas-public-data/observations/\")\n",
        "else:\n",
        "    print(\"\\n‚ùå No files created (no observations in range)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyITS3oiHi4P"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö Reference: Column Definitions\n",
        "\n",
        "### Full Dataset (`observations_MPEC.csv`)\n",
        "\n",
        "| Column | Type | Description | Units |\n",
        "|--------|------|-------------|-------|\n",
        "| `timestamp_utc` | string | UTC observation time | ISO 8601 format |\n",
        "| `observatory_code` | string | MPC 3-character observatory designation | ‚Äî |\n",
        "| `ra_j2000_deg` | float | Right Ascension in J2000.0 frame | decimal degrees (0-360) |\n",
        "| `dec_j2000_deg` | float | Declination in J2000.0 frame | decimal degrees (-90 to +90) |\n",
        "| `magnitude` | float | Apparent visual magnitude | mag (nullable) |\n",
        "| `reference` | string | MPEC reference identifier | ‚Äî |\n",
        "\n",
        "### Index File (`observations_timestamp_observatory_only.csv`)\n",
        "\n",
        "| Column | Type | Description |\n",
        "|--------|------|-------------|\n",
        "| `timestamp_utc` | string | UTC observation time |\n",
        "| `observatory_code` | string | MPC observatory code |\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Related Documentation\n",
        "\n",
        "- **MPC Observatory Codes**: https://minorplanetcenter.net/iau/lists/ObsCodesF.html\n",
        "- **MPEC Format Guide**: https://minorplanetcenter.net/iau/info/MPCFormat.html\n",
        "- **J2000 Reference Frame**: https://aa.usno.navy.mil/faq/ICRS_doc\n",
        "- **3I/ATLAS Discovery**: MPEC 2025-N12\n",
        "\n",
        "---\n",
        "\n",
        "**Repository**: https://github.com/l-87hjl/3i-atlas-public-data  \n",
        "**License**: CC0 1.0 (Public Domain)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}