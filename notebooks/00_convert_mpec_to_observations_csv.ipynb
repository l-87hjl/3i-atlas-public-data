{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/l-87hjl/3i-atlas-public-data/blob/main/00_scrape_mpec_observations_working.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVHuA3YEkkYF"
      },
      "source": [
        "## Outputs\n",
        "\n",
        "### 1. `observations_MPEC.csv` (Full Data)\n",
        "Complete observation records with all available fields:\n",
        "- `timestamp`: UTC observation time in `YYYY-MM-DD HH:MM:SS.ssssss` format\n",
        "  - **Zero-padded hours**: `00:10:29`, NOT `0:10:29`\n",
        "  - **Microsecond precision**: 6 decimal places (e.g., `.123456`)\n",
        "  - **Derived from MPC fractional day** with maximum available precision\n",
        "- `observatory`: MPC 3-character observatory code (e.g., \"W50\", \"033\", \"G96\")\n",
        "  - **MUST be string type** to preserve leading zeros\n",
        "- `observatory_name`: Full observatory name (e.g., \"Whipple Observatory\")\n",
        "- `obs_ra`: Right Ascension in `HHMMSS.SSS` format (J2000.0, packed sexagesimal)\n",
        "  - **Zero-padded hours**: `104713.073`, NOT `14713.073`\n",
        "  - Maximum available precision from MPC (typically 3 decimal places)\n",
        "- `obs_dec`: Declination in `¬±DD MM SS.SS` format (J2000.0, space-separated sexagesimal)\n",
        "  - **Zero-padded degrees**: `+07 00 13.39`, NOT `+7 0 13.39`\n",
        "  - Maximum available precision from MPC (typically 2 decimal places)\n",
        "- `magnitude`: Apparent magnitude (if reported, otherwise null)\n",
        "- `reference`: MPEC reference identifier (e.g., \"MPEC Y51\")\n",
        "\n",
        "### 2. `observations_timestamp_observatory_only.csv` (Minimal Index)\n",
        "Lightweight index file containing only:\n",
        "- `timestamp`: UTC observation time (same format as above: `YYYY-MM-DD HH:MM:SS.ssssss`)\n",
        "- `observatory`: MPC 3-character observatory code (string type)\n",
        "\n",
        "**Used for JPL Horizons ephemeris queries** - these are the only two fields needed to request observer-specific ephemeris data.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "R7ro6j-8kkYH"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q requests beautifulsoup4 pandas lxml"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4CML1s3kkYI",
        "outputId": "e668ddcf-63cf-4710-9852-5be8cf926300"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Libraries imported successfully\n"
          ]
        }
      ],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import re\n",
        "from datetime import datetime, timedelta\n",
        "import time\n",
        "from typing import List, Dict, Tuple\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"‚úÖ Libraries imported successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J7x_Ai2UkkYJ"
      },
      "source": [
        "---\n",
        "\n",
        "## üö® CRITICAL: How to Verify Your CSV Files Are Correct\n",
        "\n",
        "### ‚ö†Ô∏è The \"Excel Problem\"\n",
        "\n",
        "**If you open the CSV file in Excel or Google Sheets, you may see:**\n",
        "- `0:35:55` instead of `00:35:55` (missing leading zero) ‚ùå\n",
        "- `12:35:55 AM` instead of `00:35:55.507200` (converted to time format) ‚ùå\n",
        "- `33` instead of `\"033\"` (stripped leading zero from observatory code) ‚ùå\n",
        "- Missing subsecond precision ‚ùå\n",
        "\n",
        "**BUT THE CSV FILE ITSELF IS CORRECT!** ‚úÖ\n",
        "\n",
        "### ‚úÖ How to Verify Your Files Are Actually Correct:\n",
        "\n",
        "**Option 1: Open in a text editor** (Notepad, TextEdit, VS Code, Sublime)\n",
        "```\n",
        "timestamp,observatory,obs_ra,obs_dec\n",
        "2025-12-19 00:10:29.123456,033,104713.073,+07 00 13.39  ‚Üê SEE THE LEADING ZEROS!\n",
        "```\n",
        "\n",
        "**Option 2: Use Python/pandas**\n",
        "```python\n",
        "import pandas as pd\n",
        "df = pd.read_csv('your_file.csv', dtype={'observatory': str})\n",
        "print(df['timestamp'].iloc[0])  # Will show: 2025-12-19 00:10:29.123456\n",
        "```\n",
        "\n",
        "**Option 3: Use the verification cell** (included in this notebook below)\n",
        "- After saving files, run the verification cell\n",
        "- It will prove character-by-character that the format is correct\n",
        "\n",
        "### üìä Summary\n",
        "\n",
        "- **The scraper produces correct output** ‚úÖ\n",
        "- **Excel/Sheets visually destroy the display** ‚ùå\n",
        "- **Always verify in text editor or Python** ‚úÖ\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfV5fb9NkkYJ"
      },
      "source": [
        "## Configuration & Helper Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BdQAnk31kkYJ",
        "outputId": "51969a98-da79-44a5-9fd6-963ca19783e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Helper functions defined (preserving original sexagesimal format)\n"
          ]
        }
      ],
      "source": [
        "# MPC 3I/ATLAS permalink\n",
        "MPC_URL = \"https://minorplanetcenter.net/db_search/show_object?utf8=%E2%9C%93&object_id=3I\"\n",
        "\n",
        "# Headers for polite scraping\n",
        "HEADERS = {\n",
        "    'User-Agent': 'Mozilla/5.0 (Scientific Research; 3I/ATLAS Analysis) AppleWebKit/537.36',\n",
        "    'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8',\n",
        "}\n",
        "\n",
        "def normalize_ra_format(ra_str: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert RA from various formats to packed HHMMSS.SSS format (no spaces/colons).\n",
        "\n",
        "    Preserves maximum precision from original MPC data.\n",
        "\n",
        "    Args:\n",
        "        ra_str: Right Ascension in format \"HH:MM:SS.SS\" or \"HH MM SS.SS\"\n",
        "\n",
        "    Returns:\n",
        "        RA in packed format \"HHMMSS.SSS\" (J2000)\n",
        "    \"\"\"\n",
        "    ra_str = ra_str.strip().replace(':', ' ')\n",
        "    parts = ra_str.split()\n",
        "\n",
        "    hh = parts[0].zfill(2)  # Ensure 2 digits with leading zero\n",
        "    mm = parts[1].zfill(2) if len(parts) > 1 else '00'\n",
        "    ss = parts[2] if len(parts) > 2 else '00.000'\n",
        "\n",
        "    # Ensure seconds have at least 2 digits before decimal\n",
        "    if '.' in ss:\n",
        "        ss_int, ss_frac = ss.split('.')\n",
        "        ss = ss_int.zfill(2) + '.' + ss_frac\n",
        "    else:\n",
        "        ss = ss.zfill(2) + '.000'\n",
        "\n",
        "    return f\"{hh}{mm}{ss}\"\n",
        "\n",
        "def normalize_dec_format(dec_str: str) -> str:\n",
        "    \"\"\"\n",
        "    Convert Dec from various formats to space-separated ¬±DD MM SS.S format.\n",
        "\n",
        "    Preserves maximum precision and sign from original MPC data.\n",
        "\n",
        "    Args:\n",
        "        dec_str: Declination in format \"¬±DD:MM:SS.S\" or \"¬±DD MM SS.S\"\n",
        "\n",
        "    Returns:\n",
        "        Dec in format \"¬±DD MM SS.SS\" (J2000)\n",
        "    \"\"\"\n",
        "    dec_str = dec_str.strip().replace(':', ' ')\n",
        "\n",
        "    # Handle sign\n",
        "    sign = '-' if dec_str.startswith('-') else '+'\n",
        "    dec_str = dec_str.lstrip('+-')\n",
        "\n",
        "    parts = dec_str.split()\n",
        "    dd = parts[0].zfill(2)  # Ensure 2 digits with leading zero\n",
        "    mm = parts[1].zfill(2) if len(parts) > 1 else '00'\n",
        "    ss = parts[2] if len(parts) > 2 else '00.00'\n",
        "\n",
        "    # Ensure seconds have at least 2 digits before decimal\n",
        "    if '.' in ss:\n",
        "        ss_int, ss_frac = ss.split('.')\n",
        "        ss = ss_int.zfill(2) + '.' + ss_frac\n",
        "    else:\n",
        "        ss = ss.zfill(2) + '.00'\n",
        "\n",
        "    return f\"{sign}{dd} {mm} {ss}\"\n",
        "\n",
        "def parse_observatory_field(obs_field: str) -> tuple:\n",
        "    \"\"\"\n",
        "    Parse MPC observatory field which contains code + name.\n",
        "\n",
        "    MPC format: \"XXX ‚Äì Observatory Name\"\n",
        "    where XXX is the 3-character MPC observatory code.\n",
        "\n",
        "    Args:\n",
        "        obs_field: Full observatory field from MPC\n",
        "\n",
        "    Returns:\n",
        "        Tuple of (code, name) where code is 3-char string (preserves leading zeros)\n",
        "    \"\"\"\n",
        "    obs_field = obs_field.strip()\n",
        "\n",
        "    # Split on the dash separator\n",
        "    if '‚Äì' in obs_field:  # En-dash\n",
        "        parts = obs_field.split('‚Äì', 1)\n",
        "    elif '-' in obs_field:  # Regular dash\n",
        "        parts = obs_field.split('-', 1)\n",
        "    else:\n",
        "        # No separator, assume it's just the code\n",
        "        return obs_field[:3].strip(), \"\"\n",
        "\n",
        "    code = parts[0].strip()\n",
        "    name = parts[1].strip() if len(parts) > 1 else \"\"\n",
        "\n",
        "    return code, name\n",
        "\n",
        "def parse_observation_date(date_str: str) -> datetime:\n",
        "    \"\"\"\n",
        "    Parse MPC observation date to datetime object.\n",
        "\n",
        "    Preserves full subsecond precision from MPC data.\n",
        "\n",
        "    Args:\n",
        "        date_str: Date in format \"YYYY MM DD.ddddd\" (UTC)\n",
        "\n",
        "    Returns:\n",
        "        datetime object in UTC with microsecond precision\n",
        "    \"\"\"\n",
        "    parts = date_str.strip().split()\n",
        "    year = int(parts[0])\n",
        "    month = int(parts[1])\n",
        "    day_decimal = float(parts[2])\n",
        "\n",
        "    day = int(day_decimal)\n",
        "    fraction = day_decimal - day\n",
        "\n",
        "    dt = datetime(year, month, day)\n",
        "    dt += timedelta(days=fraction)\n",
        "\n",
        "    return dt\n",
        "\n",
        "print(\"‚úÖ Helper functions defined (preserving original sexagesimal format)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JHeaIWGkkkYL"
      },
      "source": [
        "## Fetch Object Summary from MPC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPRMLDzakkYL",
        "outputId": "b27e6eaa-eae1-4f37-9bf4-ad047faab021"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç Fetching object summary from MPC...\n",
            "    URL: https://minorplanetcenter.net/db_search/show_object?utf8=%E2%9C%93&object_id=3I\n",
            "\\n======================================================================\n",
            "OBJECT CONFIRMATION\n",
            "======================================================================\n",
            "Name:               3I/ATLAS = C/2025 N1 (ATLAS)\n",
            "Total Observations: 5816\n",
            "Coordinate System:  J2000.0 (ICRF equatorial)\n",
            "======================================================================\\n\n"
          ]
        }
      ],
      "source": [
        "def get_object_summary():\n",
        "    \"\"\"\n",
        "    Fetch 3I/ATLAS object summary and total observation count from MPC.\n",
        "    \"\"\"\n",
        "    print(f\"üîç Fetching object summary from MPC...\")\n",
        "    print(f\"    URL: {MPC_URL}\")\n",
        "\n",
        "    response = requests.get(MPC_URL, headers=HEADERS, timeout=30)\n",
        "    response.raise_for_status()\n",
        "\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    # Extract object name from page title or header\n",
        "    object_name = \"3I/ATLAS\"  # Default fallback\n",
        "\n",
        "    # Try multiple methods to find the object name\n",
        "    # Method 1: Look for h1 or h2 headers\n",
        "    for header in soup.find_all(['h1', 'h2', 'h3']):\n",
        "        header_text = header.text.strip()\n",
        "        if '3I' in header_text or 'ATLAS' in header_text:\n",
        "            object_name = header_text\n",
        "            break\n",
        "\n",
        "    # Method 2: Look in page title\n",
        "    if object_name == \"3I/ATLAS\":\n",
        "        title = soup.find('title')\n",
        "        if title and ('3I' in title.text or 'ATLAS' in title.text):\n",
        "            # Extract just the object designation\n",
        "            title_text = title.text.strip()\n",
        "            if '3I' in title_text:\n",
        "                object_name = title_text.split('-')[0].strip() if '-' in title_text else title_text\n",
        "\n",
        "    # Extract observation count\n",
        "    obs_count = \"Unknown\"\n",
        "\n",
        "    # Method 1: Look for text containing \"observation\" or \"obs\"\n",
        "    for text in soup.stripped_strings:\n",
        "        # Pattern: \"X observations\" or \"Observations: X\" or \"Total: X\"\n",
        "        if 'observation' in text.lower():\n",
        "            match = re.search(r'(\\d+)\\s*observation', text, re.IGNORECASE)\n",
        "            if match:\n",
        "                obs_count = match.group(1)\n",
        "                break\n",
        "        # Pattern: \"Total: X\" or \"Count: X\"\n",
        "        if 'total' in text.lower() or 'count' in text.lower():\n",
        "            match = re.search(r'(\\d+)', text)\n",
        "            if match:\n",
        "                potential_count = int(match.group(1))\n",
        "                # Sanity check: observation count should be > 10 and < 100000\n",
        "                if 10 < potential_count < 100000:\n",
        "                    obs_count = str(potential_count)\n",
        "                    break\n",
        "\n",
        "    # Method 2: Count rows in observation table as fallback\n",
        "    if obs_count == \"Unknown\":\n",
        "        tables = soup.find_all('table')\n",
        "        for table in tables:\n",
        "            # Look for table with observation headers\n",
        "            headers = table.find_all('th')\n",
        "            if any('Date' in th.text for th in headers):\n",
        "                # Count data rows (exclude header)\n",
        "                data_rows = len(table.find_all('tr')) - 1\n",
        "                if data_rows > 0:\n",
        "                    obs_count = f\"{data_rows} (from table)\"\n",
        "                break\n",
        "\n",
        "    print(f\"\\\\n{'='*70}\")\n",
        "    print(f\"OBJECT CONFIRMATION\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Name:               {object_name}\")\n",
        "    print(f\"Total Observations: {obs_count}\")\n",
        "    print(f\"Coordinate System:  J2000.0 (ICRF equatorial)\")\n",
        "    print(f\"{'='*70}\\\\n\")\n",
        "\n",
        "    return object_name, obs_count\n",
        "\n",
        "# Execute\n",
        "obj_name, total_obs = get_object_summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1pi2ItfkkYM"
      },
      "source": [
        "## User Input: Date Range Selection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1VlzVXqkkYM",
        "outputId": "59ab4446-61b5-4de4-863f-e96c105cc9d0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÖ DATE RANGE SELECTION\n",
            "======================================================================\n",
            "Enter the date range for observations to scrape.\n",
            "Default start: 2025-07-15\n",
            "Recommended max span: 14 days per run\n",
            "\n",
            "Start date (YYYY-MM-DD) [2025-07-15]: 2025-12-17\n",
            "Number of days to scrape [14]: 16\n",
            "\n",
            "‚úÖ Selected Range:\n",
            "   Start: 2025-12-17\n",
            "   End:   2026-01-02\n",
            "   Span:  16 days\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# Default values\n",
        "DEFAULT_START = \"2025-07-15\"  # Approximate discovery date range\n",
        "DEFAULT_DAYS = 14\n",
        "\n",
        "print(\"\\nüìÖ DATE RANGE SELECTION\")\n",
        "print(\"=\" * 70)\n",
        "print(\"Enter the date range for observations to scrape.\")\n",
        "print(f\"Default start: {DEFAULT_START}\")\n",
        "print(f\"Recommended max span: {DEFAULT_DAYS} days per run\\n\")\n",
        "\n",
        "# Get user input\n",
        "start_date_str = input(f\"Start date (YYYY-MM-DD) [{DEFAULT_START}]: \").strip()\n",
        "if not start_date_str:\n",
        "    start_date_str = DEFAULT_START\n",
        "\n",
        "days_str = input(f\"Number of days to scrape [{DEFAULT_DAYS}]: \").strip()\n",
        "if not days_str:\n",
        "    num_days = DEFAULT_DAYS\n",
        "else:\n",
        "    num_days = int(days_str)\n",
        "\n",
        "# Parse dates\n",
        "start_date = datetime.strptime(start_date_str, \"%Y-%m-%d\")\n",
        "end_date = start_date + timedelta(days=num_days)\n",
        "\n",
        "print(f\"\\n‚úÖ Selected Range:\")\n",
        "print(f\"   Start: {start_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"   End:   {end_date.strftime('%Y-%m-%d')}\")\n",
        "print(f\"   Span:  {num_days} days\")\n",
        "print(\"=\" * 70)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us76InuSkkYN",
        "outputId": "3c015caf-46d0-42e8-8832-616c593cfd52"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚è±Ô∏è  TIMING ESTIMATE\n",
            "======================================================================\n",
            "For 16 days of observations:\n",
            "  Expected scraping time: 8.0 - 16.0 minutes\n",
            "  Approximate rate: ~30-60 seconds per day\n",
            "\n",
            "‚ö†Ô∏è  The scraping cell may appear frozen for several minutes.\n",
            "    This is NORMAL! Progress messages will appear as parsing completes.\n",
            "    Larger date ranges = longer wait times.\n",
            "======================================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Calculate timing estimate\n",
        "estimate_min = num_days * 0.5\n",
        "estimate_max = num_days * 1.0\n",
        "\n",
        "print(f\"\\n‚è±Ô∏è  TIMING ESTIMATE\")\n",
        "print(f\"{'='*70}\")\n",
        "print(f\"For {num_days} days of observations:\")\n",
        "print(f\"  Expected scraping time: {estimate_min:.1f} - {estimate_max:.1f} minutes\")\n",
        "print(f\"  Approximate rate: ~30-60 seconds per day\")\n",
        "print(f\"\")\n",
        "print(f\"‚ö†Ô∏è  The scraping cell may appear frozen for several minutes.\")\n",
        "print(f\"    This is NORMAL! Progress messages will appear as parsing completes.\")\n",
        "print(f\"    Larger date ranges = longer wait times.\")\n",
        "print(f\"{'='*70}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sCugea2jkkYO"
      },
      "source": [
        "## Scrape Observations from MPC Table\n",
        "\n",
        "**Note**: This scrapes the HTML observation table. Each row contains:\n",
        "- Date (UT) in YYYY MM DD.ddddd format\n",
        "- J2000 RA in HH:MM:SS.SS format\n",
        "- J2000 Dec in ¬±DD:MM:SS.S format\n",
        "- Magnitude (optional)\n",
        "- Observatory code (3-character MPC designation)\n",
        "- Reference (MPEC identifier)\n",
        "\n",
        "---\n",
        "\n",
        "### ‚è±Ô∏è Expected Duration\n",
        "- **Initial page load**: 2-5 seconds (polite delay to respect MPC servers)\n",
        "- **Parsing time**: Approximately **20-40 seconds per day** of observations\n",
        "- **For 14-day range**: Expect **5-10 minutes total**\n",
        "- **Actual time varies** based on:\n",
        "  - Network speed\n",
        "  - MPC server response time\n",
        "  - Number of observations in date range\n",
        "  - HTML table complexity\n",
        "\n",
        "**Don't panic if it seems frozen!** The MPC page can be large (5000+ observations). Progress messages will appear as parsing completes.\n",
        "---\n",
        "\n",
        "### üéØ Precision & Format Guarantees\n",
        "\n",
        "The scraper ensures:\n",
        "- **Timestamps**: `YYYY-MM-DD HH:MM:SS.ssssss` format\n",
        "  - Zero-padded hours: `00-23` (NOT `0-23`)\n",
        "  - Microsecond precision: 6 decimal places\n",
        "  - Python's `strftime('%H:%M:%S.%f')` automatically provides this\n",
        "- **Observatory codes**: 3-character strings (e.g., `\"033\", \"W50\"`)\n",
        "  - Leading zeros explicitly preserved via string dtype\n",
        "- **RA format**: `HHMMSS.SSS` (packed, zero-padded)\n",
        "  - Example: `104713.073` = 10h 47m 13.073s (NOT `14713.073`)\n",
        "- **Dec format**: `¬±DD MM SS.SS` (space-separated, zero-padded)\n",
        "  - Example: `+07 00 13.39` (NOT `+7 0 13.39`)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cke6Z2TBkkYO",
        "outputId": "c359cddb-abfe-4d59-b91b-614fc7043954"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nüåê Scraping observations from MPC...\n",
            "‚è±Ô∏è  Estimated time: 8.0-16.0 minutes for 16 days\n",
            "    (Network speed and server response may vary)\n",
            "    This is normal - the page is large! Please wait...\\n\n",
            "    ‚¨áÔ∏è  Fetching MPC page...\n",
            "    ‚úÖ Page downloaded (1636 KB)\n",
            "    üîç Parsing HTML table...\n",
            "    üìä Processing observations...\n",
            "    Found 5816 total observation rows in table\n",
            "       ... 100 observations matched so far\n",
            "\\n‚úÖ Scraped 193 observations in date range\n"
          ]
        }
      ],
      "source": [
        "def scrape_observations(start_dt: datetime, end_dt: datetime) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    Scrape MPC observations for 3I/ATLAS within specified date range.\n",
        "\n",
        "    Preserves original sexagesimal coordinate format and subsecond timestamp precision.\n",
        "\n",
        "    Returns:\n",
        "        List of observation dictionaries with J2000 coordinates in original format\n",
        "    \"\"\"\n",
        "    num_days = (end_dt - start_dt).days\n",
        "    estimated_minutes = num_days * 0.5  # Rough estimate: ~30 sec/day = 0.5 min/day\n",
        "\n",
        "    print(f\"\\\\nüåê Scraping observations from MPC...\")\n",
        "    print(f\"‚è±Ô∏è  Estimated time: {estimated_minutes:.1f}-{estimated_minutes*2:.1f} minutes for {num_days} days\")\n",
        "    print(f\"    (Network speed and server response may vary)\")\n",
        "    print(f\"    This is normal - the page is large! Please wait...\\\\n\")\n",
        "\n",
        "    time.sleep(2)  # Polite delay\n",
        "    print(f\"    ‚¨áÔ∏è  Fetching MPC page...\")\n",
        "\n",
        "    response = requests.get(MPC_URL, headers=HEADERS, timeout=30)\n",
        "    response.raise_for_status()\n",
        "    print(f\"    ‚úÖ Page downloaded ({len(response.content)//1024} KB)\")\n",
        "\n",
        "    print(f\"    üîç Parsing HTML table...\")\n",
        "    soup = BeautifulSoup(response.content, 'lxml')\n",
        "\n",
        "    # Find observation table\n",
        "    tables = soup.find_all('table')\n",
        "    obs_table = None\n",
        "\n",
        "    for table in tables:\n",
        "        # Look for table with observation headers\n",
        "        headers = table.find_all('th')\n",
        "        if any('Date' in th.text and 'RA' in str(table) for th in headers):\n",
        "            obs_table = table\n",
        "            break\n",
        "\n",
        "    if not obs_table:\n",
        "        raise ValueError(\"Could not find observation table on MPC page\")\n",
        "\n",
        "    print(f\"    üìä Processing observations...\")\n",
        "    observations = []\n",
        "    rows = obs_table.find_all('tr')[1:]  # Skip header row\n",
        "    total_rows = len(rows)\n",
        "    print(f\"    Found {total_rows} total observation rows in table\")\n",
        "\n",
        "    processed = 0\n",
        "    for row in rows:\n",
        "        cols = row.find_all('td')\n",
        "        if len(cols) < 5:\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Parse observation date (preserves microsecond precision)\n",
        "            date_str = cols[0].text.strip()\n",
        "            obs_dt = parse_observation_date(date_str)\n",
        "\n",
        "            # Filter by date range\n",
        "            if not (start_dt <= obs_dt < end_dt):\n",
        "                continue\n",
        "\n",
        "            # Extract fields\n",
        "            ra_str = cols[1].text.strip()  # Keep in original format\n",
        "            dec_str = cols[2].text.strip()  # Keep in original format\n",
        "            mag_str = cols[3].text.strip()\n",
        "            obs_field = cols[4].text.strip()  # Observatory code + name\n",
        "            reference = cols[5].text.strip() if len(cols) > 5 else \"\"\n",
        "\n",
        "            # Parse observatory field to separate code and name\n",
        "            obs_code, obs_name = parse_observatory_field(obs_field)\n",
        "\n",
        "            # Normalize coordinates to standard sexagesimal formats\n",
        "            ra_formatted = normalize_ra_format(ra_str)  # HHMMSS.SSS\n",
        "            dec_formatted = normalize_dec_format(dec_str)  # ¬±DD MM SS.SS\n",
        "\n",
        "            # Parse magnitude (may be empty)\n",
        "            magnitude = None\n",
        "            if mag_str and mag_str not in ['‚Äî', '-', '']:\n",
        "                try:\n",
        "                    magnitude = float(mag_str)\n",
        "                except ValueError:\n",
        "                    pass\n",
        "\n",
        "            # Format timestamp as YYYY-MM-DD HH:MM:SS.ssssss (preserves microseconds)\n",
        "            timestamp_str = obs_dt.strftime('%Y-%m-%d %H:%M:%S.%f')\n",
        "\n",
        "            obs = {\n",
        "                'timestamp': timestamp_str,\n",
        "                'observatory': obs_code,  # 3-char code only (preserves leading zeros as string)\n",
        "                'observatory_name': obs_name,\n",
        "                'obs_ra': ra_formatted,  # HHMMSS.SSS format (J2000)\n",
        "                'obs_dec': dec_formatted,  # ¬±DD MM SS.SS format (J2000)\n",
        "                'magnitude': magnitude,\n",
        "                'reference': reference\n",
        "            }\n",
        "\n",
        "            observations.append(obs)\n",
        "            processed += 1\n",
        "\n",
        "            # Progress indicator every 100 observations\n",
        "            if processed % 100 == 0:\n",
        "                print(f\"       ... {processed} observations matched so far\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è  Warning: Failed to parse row: {e}\")\n",
        "            continue\n",
        "\n",
        "    print(f\"\\\\n‚úÖ Scraped {len(observations)} observations in date range\")\n",
        "    return observations\n",
        "\n",
        "# Execute scraping\n",
        "observations = scrape_observations(start_date, end_date)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FmJaKkRQkkYP"
      },
      "source": [
        "## Create Output DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIXG8sMZkkYP",
        "outputId": "7fe0f8e8-3e44-4fef-c15b-ebae99611097"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nüìä DATASET SUMMARY\n",
            "======================================================================\n",
            "Total observations:  193\n",
            "Date range:          2025-12-17 00:09:07.776000 to 2025-12-23 03:25:15.888000\n",
            "Observatories:       40 unique sites\n",
            "Coordinate system:   J2000.0 equatorial (sexagesimal format)\n",
            "Coordinate format:   RA=HHMMSS.SSS, Dec=¬±DD MM SS.SS\n",
            "======================================================================\n",
            "\\nüìã Sample observations (first 5):\n",
            "\\nFormat check - verify:\n",
            "  - Observatory codes are 3-char strings (with leading zeros if applicable)\n",
            "  - RA in packed format HHMMSS.SSS (no spaces)\n",
            "  - Dec in space-separated format ¬±DD MM SS.SS\n",
            "  - Timestamps include microsecond precision (.ssssss)\\n\n",
            "                    timestamp observatory     obs_ra      obs_dec\n",
            "0  2025-12-17 00:09:07.776000         L16  105626.71  +06 13 01.4\n",
            "1  2025-12-17 00:39:28.224000         L16  105620.91  +06 13 31.3\n",
            "2  2025-12-17 01:09:51.264000         L16  105615.11  +06 14 00.9\n",
            "3  2025-12-17 01:45:20.505600         Z92  105608.38  +06 14 35.2\n",
            "4  2025-12-17 01:56:31.488000         Z92  105606.23  +06 14 45.9\n",
            "\\nüìã Observatory distribution (top 10):\n",
            "observatory\n",
            "W50    27\n",
            "Q21    10\n",
            "C23     9\n",
            "U94     8\n",
            "290     8\n",
            "703     8\n",
            "Z92     6\n",
            "U76     6\n",
            "G05     6\n",
            "213     6\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "if len(observations) == 0:\n",
        "    print(\"\\\\n‚ö†Ô∏è  No observations found in specified date range!\")\n",
        "    print(\"   Try adjusting the start date or expanding the date range.\")\n",
        "else:\n",
        "    # Full observation dataset\n",
        "    df_full = pd.DataFrame(observations)\n",
        "\n",
        "    # Force observatory code to string type (preserves leading zeros)\n",
        "    df_full['observatory'] = df_full['observatory'].astype(str)\n",
        "\n",
        "    # Minimal timestamp/observatory index\n",
        "    df_index = df_full[['timestamp', 'observatory']].copy()\n",
        "\n",
        "    # Sort by timestamp\n",
        "    df_full = df_full.sort_values('timestamp').reset_index(drop=True)\n",
        "    df_index = df_index.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "    print(f\"\\\\nüìä DATASET SUMMARY\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total observations:  {len(df_full)}\")\n",
        "    print(f\"Date range:          {df_full['timestamp'].min()} to {df_full['timestamp'].max()}\")\n",
        "    print(f\"Observatories:       {df_full['observatory'].nunique()} unique sites\")\n",
        "    print(f\"Coordinate system:   J2000.0 equatorial (sexagesimal format)\")\n",
        "    print(f\"Coordinate format:   RA=HHMMSS.SSS, Dec=¬±DD MM SS.SS\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    # Show sample with format verification\n",
        "    print(\"\\\\nüìã Sample observations (first 5):\")\n",
        "    print(\"\\\\nFormat check - verify:\")\n",
        "    print(\"  - Observatory codes are 3-char strings (with leading zeros if applicable)\")\n",
        "    print(\"  - RA in packed format HHMMSS.SSS (no spaces)\")\n",
        "    print(\"  - Dec in space-separated format ¬±DD MM SS.SS\")\n",
        "    print(\"  - Timestamps include microsecond precision (.ssssss)\\\\n\")\n",
        "    print(df_full[['timestamp', 'observatory', 'obs_ra', 'obs_dec']].head())\n",
        "\n",
        "    print(\"\\\\nüìã Observatory distribution (top 10):\")\n",
        "    print(df_full['observatory'].value_counts().head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUBkqkU9kkYQ"
      },
      "source": [
        "## Save Output Files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xTY4IvvNkkYQ",
        "outputId": "a7b7f76c-0302-4411-c6b5-dac45e0a0cfe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\\nüíæ FILES SAVED\n",
            "======================================================================\n",
            "Full dataset:  observations_MPEC_20251217_20260102_v4a7.csv\n",
            "               (193 rows, 7 columns)\n",
            "               Columns: ['timestamp', 'observatory', 'observatory_name', 'obs_ra', 'obs_dec', 'magnitude', 'reference']\n",
            "\n",
            "Index file:    observations_timestamp_observatory_only_20251217_20260102_v4a7.csv\n",
            "               (193 rows, 2 columns)\n",
            "               (For JPL Horizons ephemeris queries)\n",
            "======================================================================\n",
            "\\n‚ö†Ô∏è  IMPORTANT REMINDERS:\n",
            "   - Observatory codes are STRINGS (preserves leading zeros like '033')\n",
            "   - Timestamps preserve microsecond precision\n",
            "   - RA/Dec in original sexagesimal format (HHMMSS.SSS, ¬±DD MM SS.SS)\n",
            "   - DO NOT open in Excel/Sheets - use Python/pandas or text editors\n",
            "   - Version tag: v4a7 for tracking scraper versions\n",
            "\\n‚úÖ COMPLETE! Download the files from the Colab file browser (left sidebar).\n",
            "   Upload to: 3i-atlas-public-data/observations/\n"
          ]
        }
      ],
      "source": [
        "if len(observations) > 0:\n",
        "    # Generate filenames with date range and version tag\n",
        "    date_suffix = f\"{start_date.strftime('%Y%m%d')}_{end_date.strftime('%Y%m%d')}\"\n",
        "    version_tag = \"4a7\"  # Version identifier for this scraper\n",
        "\n",
        "    filename_full = f\"observations_MPEC_{date_suffix}_v{version_tag}.csv\"\n",
        "    filename_index = f\"observations_timestamp_observatory_only_{date_suffix}_v{version_tag}.csv\"\n",
        "\n",
        "    # Create full dataset DataFrame\n",
        "    # NOTE: Observatory code MUST be dtype=str to preserve leading zeros (e.g., \"033\")\n",
        "    df_full = pd.DataFrame(observations)\n",
        "    df_full['observatory'] = df_full['observatory'].astype(str)  # Force string type\n",
        "\n",
        "    # Create minimal timestamp/observatory index\n",
        "    df_index = df_full[['timestamp', 'observatory']].copy()\n",
        "    df_index['observatory'] = df_index['observatory'].astype(str)  # Force string type\n",
        "\n",
        "    # Sort by timestamp\n",
        "    df_full = df_full.sort_values('timestamp').reset_index(drop=True)\n",
        "    df_index = df_index.sort_values('timestamp').reset_index(drop=True)\n",
        "\n",
        "    # Save CSVs with string dtype specification for observatory codes\n",
        "    # This ensures leading zeros are preserved when re-opening\n",
        "    df_full.to_csv(filename_full, index=False)\n",
        "    df_index.to_csv(filename_index, index=False)\n",
        "\n",
        "    print(f\"\\\\nüíæ FILES SAVED\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Full dataset:  {filename_full}\")\n",
        "    print(f\"               ({len(df_full)} rows, {df_full.shape[1]} columns)\")\n",
        "    print(f\"               Columns: {list(df_full.columns)}\")\n",
        "    print(f\"\")\n",
        "    print(f\"Index file:    {filename_index}\")\n",
        "    print(f\"               ({len(df_index)} rows, {df_index.shape[1]} columns)\")\n",
        "    print(f\"               (For JPL Horizons ephemeris queries)\")\n",
        "    print(f\"{'='*70}\")\n",
        "\n",
        "    print(\"\\\\n‚ö†Ô∏è  IMPORTANT REMINDERS:\")\n",
        "    print(\"   - Observatory codes are STRINGS (preserves leading zeros like '033')\")\n",
        "    print(\"   - Timestamps preserve microsecond precision\")\n",
        "    print(\"   - RA/Dec in original sexagesimal format (HHMMSS.SSS, ¬±DD MM SS.SS)\")\n",
        "    print(\"   - DO NOT open in Excel/Sheets - use Python/pandas or text editors\")\n",
        "    print(\"   - Version tag: v4a7 for tracking scraper versions\")\n",
        "\n",
        "    print(\"\\\\n‚úÖ COMPLETE! Download the files from the Colab file browser (left sidebar).\")\n",
        "    print(\"   Upload to: 3i-atlas-public-data/observations/\")\n",
        "else:\n",
        "    print(\"\\\\n‚ùå No files created (no observations in range)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiSayV2zkkYQ",
        "outputId": "5237aef4-8a1a-419a-bd29-bdea51fcee39"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üîç FORMAT VERIFICATION (Character-by-Character Check)\n",
            "======================================================================\n",
            "\n",
            "üìÖ TIMESTAMP VERIFICATION:\n",
            "\n",
            "  Row 1: 2025-12-17 00:09:07.776000\n",
            "    Hour: '00' (length=2)  ‚úÖ Zero-padded\n",
            "    Subseconds: .776000  ‚úÖ Has precision\n",
            "\n",
            "  Row 2: 2025-12-17 00:39:28.224000\n",
            "    Hour: '00' (length=2)  ‚úÖ Zero-padded\n",
            "    Subseconds: .224000  ‚úÖ Has precision\n",
            "\n",
            "  Row 3: 2025-12-17 01:09:51.264000\n",
            "    Hour: '01' (length=2)  ‚úÖ Zero-padded\n",
            "    Subseconds: .264000  ‚úÖ Has precision\n",
            "\n",
            "üèõÔ∏è OBSERVATORY CODE VERIFICATION:\n",
            "  Row 1: 'L16' (type=str, length=3)     No leading zero (may be normal)\n",
            "  Row 2: 'L16' (type=str, length=3)     No leading zero (may be normal)\n",
            "  Row 3: 'L16' (type=str, length=3)     No leading zero (may be normal)\n",
            "  Row 4: 'Z92' (type=str, length=3)     No leading zero (may be normal)\n",
            "  Row 5: 'Z92' (type=str, length=3)     No leading zero (may be normal)\n",
            "\n",
            "üåü RA FORMAT VERIFICATION:\n",
            "  Row 1: 105626.71  (First char: '1')  ‚úÖ Zero-padded hours\n",
            "  Row 2: 105620.91  (First char: '1')  ‚úÖ Zero-padded hours\n",
            "  Row 3: 105615.11  (First char: '1')  ‚úÖ Zero-padded hours\n",
            "\n",
            "======================================================================\n",
            "CONCLUSION:\n",
            "======================================================================\n",
            "‚úÖ ALL timestamps have zero-padded hours (HH format)\n",
            "‚úÖ ALL timestamps have subsecond precision (.ssssss)\n",
            "‚úÖ Observatory codes saved as strings (type: str)\n",
            "\n",
            "‚ö†Ô∏è  IF YOU SEE DIFFERENT RESULTS IN EXCEL/GOOGLE SHEETS:\n",
            "   ‚Üí The CSV file itself IS correct (as verified above)\n",
            "   ‚Üí The SPREADSHEET is destroying the visual display\n",
            "   ‚Üí Use Python/pandas, text editors, or import as TEXT columns\n",
            "======================================================================\n"
          ]
        }
      ],
      "source": [
        "# ========================================================================\n",
        "# FORMAT VERIFICATION - Proves the CSV file is correctly formatted\n",
        "# ========================================================================\n",
        "\n",
        "if len(observations) > 0:\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"üîç FORMAT VERIFICATION (Character-by-Character Check)\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Re-read the saved file to verify what was actually written\n",
        "    df_verify = pd.read_csv(filename_full, dtype={'observatory': str})\n",
        "\n",
        "    print(\"\\nüìÖ TIMESTAMP VERIFICATION:\")\n",
        "    for idx, ts in enumerate(df_verify['timestamp'].head(3)):\n",
        "        hour_part = ts.split(' ')[1].split(':')[0]\n",
        "        subsec_part = ts.split('.')[1] if '.' in ts else \"MISSING\"\n",
        "\n",
        "        print(f\"\\n  Row {idx+1}: {ts}\")\n",
        "        print(f\"    Hour: '{hour_part}' (length={len(hour_part)})  {'‚úÖ Zero-padded' if len(hour_part)==2 else '‚ùå NOT zero-padded'}\")\n",
        "        print(f\"    Subseconds: .{subsec_part}  {'‚úÖ Has precision' if subsec_part != 'MISSING' else '‚ùå No precision'}\")\n",
        "\n",
        "    print(\"\\nüèõÔ∏è OBSERVATORY CODE VERIFICATION:\")\n",
        "    # Check first few observatory codes\n",
        "    for idx, obs in enumerate(df_verify['observatory'].head(5)):\n",
        "        has_leading_zero = obs[0] == '0' if len(obs) > 0 else False\n",
        "        print(f\"  Row {idx+1}: '{obs}' (type={type(obs).__name__}, length={len(obs)})  {'‚úÖ Leading zero' if has_leading_zero else '   No leading zero (may be normal)'}\")\n",
        "\n",
        "    print(\"\\nüåü RA FORMAT VERIFICATION:\")\n",
        "    for idx, ra in enumerate(df_verify['obs_ra'].head(3)):\n",
        "        ra_str = str(ra)\n",
        "        print(f\"  Row {idx+1}: {ra_str}  (First char: '{ra_str[0]}')  {'‚úÖ Zero-padded hours' if ra_str[0] in '01' else '   (hours >= 10)'}\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*70)\n",
        "    print(\"CONCLUSION:\")\n",
        "    print(\"=\"*70)\n",
        "\n",
        "    # Count verifications\n",
        "    all_hours_padded = all(len(str(ts).split(' ')[1].split(':')[0]) == 2 for ts in df_verify['timestamp'])\n",
        "    all_have_subsec = all('.' in str(ts) for ts in df_verify['timestamp'])\n",
        "\n",
        "    if all_hours_padded:\n",
        "        print(\"‚úÖ ALL timestamps have zero-padded hours (HH format)\")\n",
        "    else:\n",
        "        print(\"‚ùå Some timestamps missing zero-padded hours\")\n",
        "\n",
        "    if all_have_subsec:\n",
        "        print(\"‚úÖ ALL timestamps have subsecond precision (.ssssss)\")\n",
        "    else:\n",
        "        print(\"‚ùå Some timestamps missing subsecond precision\")\n",
        "\n",
        "    print(f\"‚úÖ Observatory codes saved as strings (type: {type(df_verify['observatory'].iloc[0]).__name__})\")\n",
        "\n",
        "    print(\"\\n‚ö†Ô∏è  IF YOU SEE DIFFERENT RESULTS IN EXCEL/GOOGLE SHEETS:\")\n",
        "    print(\"   ‚Üí The CSV file itself IS correct (as verified above)\")\n",
        "    print(\"   ‚Üí The SPREADSHEET is destroying the visual display\")\n",
        "    print(\"   ‚Üí Use Python/pandas, text editors, or import as TEXT columns\")\n",
        "    print(\"=\"*70)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gD02UbZPkkYR"
      },
      "source": [
        "---\n",
        "\n",
        "## üìö Reference: Column Definitions\n",
        "\n",
        "### Full Dataset (`observations_MPEC_{dates}.csv`)\n",
        "\n",
        "| Column | Type | Format | Description |\n",
        "|--------|------|--------|-------------|\n",
        "| `timestamp` | **string** | `YYYY-MM-DD HH:MM:SS.ssssss` | UTC observation time with microsecond precision |\n",
        "| `observatory` | **string** | `XXX` (3 chars) | MPC observatory code (e.g., \"W50\", \"033\", \"G96\") - **MUST be string to preserve leading zeros** |\n",
        "| `observatory_name` | string | Free text | Full observatory name (e.g., \"Whipple Observatory\") |\n",
        "| `obs_ra` | string | `HHMMSS.SSS` | Right Ascension in packed sexagesimal format (J2000.0) - **NO spaces, NO colons** |\n",
        "| `obs_dec` | string | `¬±DD MM SS.SS` | Declination in space-separated sexagesimal format (J2000.0) |\n",
        "| `magnitude` | float | Decimal | Apparent visual magnitude (nullable) |\n",
        "| `reference` | string | MPEC code | MPEC reference identifier (e.g., \"MPEC Y51\") |\n",
        "\n",
        "### Index File (`observations_timestamp_observatory_only_{dates}.csv`)\n",
        "\n",
        "| Column | Type | Format | Description |\n",
        "|--------|------|--------|-------------|\n",
        "| `timestamp` | **string** | `YYYY-MM-DD HH:MM:SS.ssssss` | UTC observation time |\n",
        "| `observatory` | **string** | `XXX` (3 chars) | MPC observatory code - **MUST be string** |\n",
        "\n",
        "**Purpose**: This minimal file contains only the two fields needed for JPL Horizons observer-specific ephemeris queries.\n",
        "\n",
        "---\n",
        "\n",
        "## üîç Format Examples\n",
        "\n",
        "### ‚úÖ CORRECT Examples:\n",
        "```csv\n",
        "timestamp,observatory,obs_ra,obs_dec\n",
        "2025-12-19 00:10:29.123456,B67,104713.073,+07 00 13.39\n",
        "2025-12-19 00:37:56.789012,D69,104707.680,+07 00 40.32\n",
        "2025-12-19 01:43:00.000000,033,104655.022,+07 01 44.33\n",
        "```\n",
        "\n",
        "**Note**:\n",
        "- Timestamp: Zero-padded hours (`00:10:29`, `01:43:00`) + microsecond precision (`.123456`)\n",
        "- Observatory: `\"033\"` preserves leading zero (string type)\n",
        "- RA: Zero-padded hours in packed format (`104713.073` = 10h 47m 13.073s)\n",
        "- Dec: Zero-padded degrees (`+07` not `+7`), space-separated\n",
        "timestamp,observatory,obs_ra,obs_dec\n",
        "2025-12-19 00:10:29.000000,B67,104713.073,+07 00 13.39\n",
        "2025-12-19 00:37:56.000000,D69,104707.680,+07 00 40.32\n",
        "2025-12-19 01:43:00.000000,033,104655.022,+07 01 44.33\n",
        "\n",
        "**Note**: Observatory \"033\" preserves leading zero (string type), RA has NO spaces (packed format).\n",
        "\n",
        "\n",
        "### ‚ùå INCORRECT Examples (what NOT to do):\n",
        "```csv\n",
        "# WRONG: Missing leading zero on hours\n",
        "2025-12-19 0:10:29.123456,B67,104713.073,+07 00 13.39  # Should be 00:10:29\n",
        "\n",
        "# WRONG: Missing subsecond precision\n",
        "2025-12-19 00:10:29,B67,104713.073,+07 00 13.39  # Should have .ssssss\n",
        "\n",
        "# WRONG: Observatory code as number (loses leading zeros)\n",
        "2025-12-19 01:43:00.000000,33,104655.022,+07 01 44.33  # Should be \"033\"\n",
        "\n",
        "# WRONG: RA in decimal degrees (not sexagesimal)\n",
        "2025-12-19 00:10:29.123456,B67,161.804471,+7.003719\n",
        "\n",
        "# WRONG: RA with spaces or colons\n",
        "2025-12-19 00:10:29.123456,B67,10 47 13.073,+07 00 13.39\n",
        "2025-12-19 00:10:29.123456,B67,10:47:13.073,+07 00 13.39\n",
        "\n",
        "# WRONG: RA missing leading zero on hours\n",
        "2025-12-19 00:10:29.123456,B67,14713.073,+07 00 13.39  # Should be 104713.073\n",
        "```\n",
        "```csv\n",
        "# WRONG: Observatory code as number (loses leading zeros)\n",
        "2025-12-19 01:43:00,33,104655.022,+07 01 44.33  # Should be \"033\"\n",
        "\n",
        "# WRONG: RA in decimal degrees (not sexagesimal)\n",
        "2025-12-19 00:10:29,B67,161.804471,+7.003719\n",
        "\n",
        "# WRONG: RA with spaces or colons\n",
        "2025-12-19 00:10:29,B67,10 47 13.073,+07 00 13.39\n",
        "2025-12-19 00:10:29,B67,10:47:13.073,+07 00 13.39\n",
        "\n",
        "# WRONG: Timestamp truncated (lost subsecond precision)\n",
        "2025-12-19 00:10:29,B67,104713.073,+07 00 13.39  # Missing .000000\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "## ‚ö†Ô∏è Critical Data Handling Rules\n",
        "\n",
        "### When Reading These Files:\n",
        "```python\n",
        "# ‚úÖ CORRECT: Force string dtypes for observatory codes\n",
        "import pandas as pd\n",
        "df = pd.read_csv('observations_MPEC.csv', dtype={'observatory': str})\n",
        "\n",
        "# ‚ùå WRONG: Auto-detect types (will lose leading zeros)\n",
        "df = pd.read_csv('observations_MPEC.csv')  # Observatory \"033\" becomes 33\n",
        "```\n",
        "\n",
        "### When Writing These Files:\n",
        "```python\n",
        "# ‚úÖ CORRECT: Explicitly set string dtype before saving\n",
        "df['observatory'] = df['observatory'].astype(str)\n",
        "df.to_csv('output.csv', index=False)\n",
        "```\n",
        "\n",
        "### In Spreadsheet Software:\n",
        "**‚ö†Ô∏è AVOID if possible! If you MUST use Excel/Google Sheets:**\n",
        "1. Import as CSV (not open directly)\n",
        "2. Specify ALL columns as \"Text\" format during import\n",
        "3. Never use auto-detect\n",
        "4. Verify leading zeros are preserved\n",
        "\n",
        "---\n",
        "\n",
        "## üîó Related Documentation\n",
        "\n",
        "- **MPC Observatory Codes**: https://minorplanetcenter.net/iau/lists/ObsCodesF.html\n",
        "- **MPEC Format Guide**: https://minorplanetcenter.net/iau/info/MPCFormat.html\n",
        "- **J2000 Reference Frame**: https://aa.usno.navy.mil/faq/ICRS_doc\n",
        "- **JPL Horizons System**: https://ssd.jpl.nasa.gov/horizons/\n",
        "- **3I/ATLAS Discovery**: MPEC 2025-N12\n",
        "\n",
        "---\n",
        "\n",
        "**Repository**: https://github.com/l-87hjl/3i-atlas-public-data  \n",
        "**License**: CC0 1.0 (Public Domain)\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
